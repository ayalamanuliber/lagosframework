I Let An AI Handle My First Pro Bono Case (And Nearly Got Disbarred)

I still get sweaty palms thinking about that ethics board hearing.

This isn't one of those "AI is dangerous" fear-mongering posts. It's just me, telling you about the dumbest decision I made in my legal career, hoping you won't repeat my mistakes.

It started because I was drowning. Second year at my firm, billing 280 hours a month, living on energy drinks and takeout. Then this pro bono case landed on my desk - housing discrimination, elderly client, real heart-wrenching stuff.

I wanted to help. I really did. But between the M&A deal eating my life and my senior partner breathing down my neck about billables, I was barely keeping my head above water.

Then I remembered that fancy new AI legal assistant the firm bought. The one that was supposed to "revolutionize legal work" or whatever the sales pitch said. I figured - hey, pro bono case, good cause to test it out, right?

God, I was an idiot.

First few weeks were fine. The AI helped draft routine motions, did initial research. Basic stuff. I'd skim, make a few tweaks, file. My client - let's call her Mrs. J - seemed happy enough.

Then came the preliminary hearing. I walked in confident, AI-generated briefs in hand.

The opposing counsel brought up a local ordinance I'd never heard of. No big deal, I thought. My AI research had been thorough.

Except it hadn't.

The ordinance had been amended three months ago. The AI was pulling from outdated databases. Every single argument in my beautifully-formatted brief was based on defunct law.

I can still hear the judge's voice: "Counselor, are you aware this ordinance was significantly modified last quarter?"

My stomach dropped through the floor. Mrs. J, who'd taken three buses to get to court, was sitting right behind me.

I'd love to tell you I brilliantly recovered. I didn't. I stammered something about needing time to review the current statute. The judge's face said it all.

That night, I actually read the case law. All of it. No AI. Just me, my laptop, and enough coffee to kill a horse.

Turns out there were three similar cases in our district. Cases the AI missed because they were too recent. Cases that could've helped Mrs. J.

The ethics board hearing was two weeks later. I self-reported. Figured they'd find out anyway.

You know what saved me? Mrs. J herself. She came to the hearing. Told them I'd been the only lawyer who returned her calls. That I'd visited her at home when she couldn't make it to my office. That I'd actually cared.

The board gave me a warning. And a lecture I'll never forget about due diligence and professional responsibility.

I still use AI tools. Be crazy not to in 2024. But now I have rules:

1. Never trust it with someone's life problems
2. Read the damn cases myself
3. Technology assists, it doesn't replace judgment
4. If I'm too busy to do it right, I'm too busy to do it

Mrs. J still sends me Christmas cards. Her case? We won it, eventually. After I put in the real work. After I stopped trying to automate caring.

Last month, a new pro bono case came across my desk. Housing discrimination again. I looked at my billables (still insane), looked at my calendar (still packed), and said yes.

But this time, I started by driving to the client's house. No AI. Just a lawyer, a notepad, and a reminder of why I went to law school in the first place.

The AI tools are still there, on my laptop. But they're like spell-check now - helpful, but not in charge.

Because here's the thing they don't teach you in law school: There's no AI for giving a damn.

P.S. I keep that old AI-generated brief in my desk drawer. Whenever I'm tempted to take shortcuts, I read it. Works better than coffee for keeping me honest.
